\section{Classification et Évaluation}

Une fois l'acquisition des données utilisateur réalisée, il reste à produire un système de vérification capable de discriminer un imposteur par rapport à un ou plusieurs utilisateurs authentiques. Les algorithmes et méthodologies utilisées varient en fonction des objectifs recherchés.

\subsection{Classification}
\subsubsection{Méthodologies}
La première étape est de construire un modèle de vérification en classant les données disponibles en plusieurs "classe" de profils. Plusieurs méthodes possibles existent pour classer les données :

\begin{itemize}
	\item Méthodes statistiques ;
	\item Algorithmes de \textit{Machine Learning} \bibentry{Hu2008};
%	\item Réseaux de neurones. À proprement parler il s'agit aussi de \textit{Machine Learning} mais la littérature a tendance à les séparer du reste car ils ont des propriétés propres et requièrent des performances bien plus importantes que les algorithmes classiques.
\end{itemize}

Parmis les algorithmes à base de \textit{machine learning} aperçus dans la littérature, nous pouvons citer :

\begin{description}
  \item[kNN\cite{Hu2008} (\textit{k-Nearest Neighbors})] Il s'agit d'un algorithme de classification qui mesure la distance entre une nouvelle donnée et les données précedemment enregistrées. On sélectionne alors les k plus proches voisins et on fait la moyenne de leur classe pour déterminer la classe de la nouvelle donnée (si sur 3 voisins plus proches, 2 d'entre eux sont de la classe 2 et un de la classe 1, alors la nouvelle donnée fait partie de la classe 2).
  \item[SVM\cite{giotSVM} (\textit{State Vector Machine})] Il s'agit d'un algorithme de classification, généralisation des classifieurs linéaires, dont les particularités sont la transformation de l'espace de représentation lorsque les données ne sont pas linéairement séparables et la maximisation de la marge au niveau des échantillons les plus proches de la frontière de décision afin de redéfinir une frontière de décision plus précise.
  \item[ANN (\textit{Artificial Neural Network})] Il s'agit d'un algorithme comprenant une couche de neurones d'entrée, une couche de neurones de sortie et une ou plusieurs couches de neurones intermédiaires. Les neurones intermédiaires agissent comme des coefficients qui sont appliqués dans une équation dont les paramètres d'entrée sont les neurones d'entrée et la sortie, la classe correspondante aux données entrées. Sa construction se révèle très simple et permet de résoudre des problèmes très complexes. Son efficacité sur des jeux de données comprenant un grand nombre d'attributs (> 50) en fait un outil de choix pour la discrimination de schémas complexes tels que des enregistrements de frappe au clavier. Il a comme désavantage d'être très gourmand en mémoire et en ressources processeurs, tant pour l'entraînement que pour la prédiction.
  \item[One-class SVM\cite{oneclassSVM}] Il s'agit d'une SVM non-supervisée. Elle est utilisée pour des tâches d'\textit{outlier detection}, c'est-à-dire la détection de données anormales, n'appartenant pas au groupe de données initial. Pour être utilisée, elle ne nécessite qu'un groupe de données appartenant à une seule classe. Elle est donc parfaitement adaptée à la détection d'un seul utilisateur en absence de données d'imposteurs.
\end{description}

Les algorithmes de \textit{machine learning} supervisés qui font de la classification multi-classe (c'est-à-dire une classification entre trois classes ou plus) sont divisés en deux types :

%http://scikit-learn.org/stable/modules/svm.html#multi-class-classification

\begin{description}
	\item[\textit{one-vs-one}] : pour chaque couple de classe, on crée un classifieur binaire. Pour classifier une nouvelle donnée, on effectue une prédiction avec tous les classifieurs et on récupère la classe ayant été la plus prédite parmis tous les classifieurs.
	\item[\textit{one-vs-rest}] : pour chaque classe, on crée un classifieur binaire dont la tâche sera de distinguer la classe concernée de toutes les autres données (qui sont alors regroupées dans une classe "autre"). Lorsqu'on veut classifier une nouvelle donnée, on effectue une prédiction avec tous les classifieurs et on récupère la classe qui n'aura pas été classifiée comme étant "autre".
\end{description}

Les algorithmes de type \textit{one-vs-one} sont utilisés lorsqu'on possède des données ayant une prépondérance d'une classe sur une autre (par exemple, une classe qui serait représentée par 80\% des échantillons), au risque d'utiliser plus de ressources processeur.

\subsubsection{Ordre de grandeur des systèmes développés}

Jusqu'ici les systèmes développés sont adaptés à quelques dizaines ou une centaines d'utilisateurs mais guère plus. Cependant dans la vraie vie, il n'est pas rare que les systèmes d'authentification contrôlent l'accès à des services pour des millions d'utilisateurs tous différents. Le problème est que certains algorithmes de classifications présentent une baisse très importantes de la fiabilité avec l'augmentation du nombre d'utilisateurs \cite{panasiuk2016}. Il y a donc un problème de ces méthodes de classification car elles ne permettent pas de développer des systèmes d'authentification qui sont adaptés à différents ordres de grandeur. C'est la raison pour laquelle nous avons choisi d'orienter notre travail sur l'authentification d'une personne unique sur un ordinateur personnel. En effet, l'essentiel des travaux du domaine proposent des systèmes éprouvés sur un nombre restreint d'utilisateurs, nous pourrons donc nous appuyer sur ces travaux. Par ailleurs, il est beaucoup plus difficile d'évaluer les performances d'un système développé pour des millions d'utilisateurs, notamment parce qu'il n'existe pas de bases de données permettant de l'éprouver.

\input{global/evaluation}
