\section{Classification/Évaluation}

Une fois l'acquisition des données utilisateur réalisée, il reste à produire un système de vérification capable de discriminer un imposteur par rapport à un ou plusieurs utilisateurs authentiques. Les algorithmes et méthodologies utilisées varient en fonction des objectifs recherchés.

\subsection{Méthodologies de classification}

La première étape est de construire un modèle de vérification en classant les données disponibles en plusieurs "classe" de profils. Plusieurs méthodes possibles existent pour classer les données :\\

\begin{itemize}
	\item Méthodes statistiques ;
	\item Algorithmes de \textit{Machine Learning} \bibentry{Hu2008};
%	\item Réseaux de neurones. À proprement parler il s'agit aussi de \textit{Machine Learning} mais la littérature a tendance à les séparer du reste car ils ont des propriétés propres et requièrent des performances bien plus importantes que les algorithmes classiques.
\end{itemize}

Parmis les algorithmes à base de \textit{machine learning} aperçus dans la littérature, nous pouvons citer :\\

\begin{description}
  \item[kNN\cite{Hu2008} (\textit{k-Nearest Neighbors})]
  \item[SVM\cite{giotSVM} (\textit{State Vector Machine})] : il s'agit d'un algorithme de classification qui généralisation des classifieurs linéaires dont les particularités sont la transformation de l'espace de représentation lorsque les données ne sont pas linéairement séparables et la maximisation de la marge au niveau des échantillons les plus proches de la frontière de décision afin de redéfinir une frontière de décision plus précise.
  \item[ANN (\textit{Artificial Neural Network})] : il s'agit d'un algorithme comprenant une couche de neurones d'entrée, une couche de neurones de sortie et une ou plusieurs couches de neurones intermédiaires. Les neurones intermédiaires agissent comme des coefficients qui sont appliqués dans une équation dont les paramètres d'entrée sont les neurones d'entrée et la sortie, la classe correspondante aux données entrée. Sa construction se révèle très simple et permet de résoudre des problèmes très complexes. Son efficacité sur des jeux de données comprenant un grand nombre d'attributs ( 50) en fait un outil de choix pour la discrimination de schémas complexes tels que des enregistrements de frappe au clavier. Il a comme désavantage d'être très gourmand en mémoire et en ressources processeurs, tant pour l'entraînement que pour la prédiction.
  \item[One-class SVM\cite{oneclassSVM}] : il s'agit d'une SVM non-supervisée. Elle est utilisée pour des tâches d'\textit{outlier detection}, c'est-à-dire la détection de données anormales, n'appartenant pas au groupe de données initial. Pour être utilisée, elle ne nécessite qu'un groupe de données appartenant à une seule classe. Elle est donc parfaitement adaptée à la détection d'un seul utilisateur en absence de données d'imposteurs.
\end{description}

% RODOLPHE: je suis pas sûr de ce passage, on aurait déjà dû dire qu'on s'intéresse uniquement à l'authentification et on a donc pas à décrire la différence authentification/identification

%Les méthodes utilisées varient aussi en fonction de l'objectif que l'on veut faire remplir au modèle de vérification :

%\begin{itemize}
%	\item une seule classe : détection des imposteurs \bibentry{killourhy2009};
%	\item une classe par utilisateur : identification de l'utilisateur parmi plusieurs \bibentry{monrose1997}.
%\end{itemize}

\subsection{Métriques}
FAR / FRR

\subsection{Ordre de grandeur des systèmes développés}

Jusqu'ici les systèmes développés sont adaptés à quelques dizaines ou une centaines d'utilisateurs mais guère plus. Cependant dans la vraie vie, il n'est pas rare que les systèmes d'authentification contrôlent l'accès à des services pour des millions d'utilisateurs tous différents. Le problème est que certains algorithmes de classifications présentent une baisse très importantes de la fiabilité avec l'augmentation du nombre d'utilisateurs \cite{panasiuk2016}. Il y a donc un problème de ces méthodes de classification car elles ne permettent pas de développer des systèmes d'authentification qui sont adaptés à différents ordres de grandeur. C'est la raison pour laquelle nous avons choisi d'orienter notre travail sur l'authentification d'une personne unique sur un ordinateur personnel. En effet, l'essentiel des travaux du domaine proposent des systèmes éprouvés sur un nombre restreint d'utilisateurs, nous pourrons donc nous appuyer sur ces travaux. Par ailleurs, il est beaucoup plus difficile d'évaluer les performances d'un système développé pour des millions d'utilisateurs, notamment parce qu'il n'existe pas de bases de données permettant de l'éprouver.
